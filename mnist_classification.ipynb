{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ¯ <b><u>Exercise objectives</u></b>\n",
    "- Understand the *MNIST* dataset \n",
    "- Design your first **Convolutional Neural Network** (*CNN*) and answer questions such as:\n",
    "    - what are *Convolutional Layers*? \n",
    "    - how many *parameters* are involved in such a layer?\n",
    "- Train this CNN on images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸš€ <b><u>Let's get started!</u></b>\n",
    "\n",
    "Imagine that we are  back in time into the 90's.\n",
    "You work at a *Post Office* and you have to deal with an enormous amount of letters on a daily basis. How could you automate the process of reading the ZIP Codes, which are a combination of 5 handwritten digits? \n",
    "\n",
    "This task, called the **Handwriting Recognition**, used to be a very complex problem back in those days. It was solved by *Bell Labs* (among others) where one of the Deep Learning gurus, [*Yann Le Cun*](https://en.wikipedia.org/wiki/Yann_LeCun), used to work.\n",
    "\n",
    "From [Wikipedia](https://en.wikipedia.org/wiki/Handwriting_recognition):\n",
    "\n",
    "> Handwriting recognition (HWR), also known as Handwritten Text Recognition (HTR), is the ability of a computer to receive and interpret intelligible handwritten input from sources such as paper documents, photographs, touch-screens and other devices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Number recognition](recognition.gif)\n",
    "\n",
    "*Note: The animation above is just here to help you visualize what happens with the different images: <br/> $\\rightarrow$ For each image, once the CNN is trained, it will predict what digit is written. The inputs are the different digits and not one animation/video!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ¤” <b><u>How does this CNN work ?</u></b>\n",
    "\n",
    "- *Inputs*: Images (_each image shows a handwritten digit_)\n",
    "- *Target*: For each image, you want your CNN model to predict the correct digit (between 0 and 9)\n",
    "    - It is a **multi-class classification** task (more precisely a 10-class classification task since there are 10 different digits).\n",
    "\n",
    "ğŸ”¢ To improve the capacity of the Convolutional Neural Network to read these numbers, we need to feed it with many images representing handwritten digits. This is why the ğŸ“š [**MNIST dataset**](http://yann.lecun.com/exdb/mnist/) *(Mixed National Institute of Standards and Technology)* was created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T09:09:23.312396Z",
     "iopub.status.busy": "2025-08-15T09:09:23.311808Z",
     "iopub.status.idle": "2025-08-15T09:09:23.339932Z",
     "shell.execute_reply": "2025-08-15T09:09:23.338725Z",
     "shell.execute_reply.started": "2025-08-15T09:09:23.312345Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Scikitlearn\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "# keras\n",
    "from keras.ops import expand_dims\n",
    "from keras.utils import to_categorical\n",
    "from keras import Sequential, Input, layers\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers.schedules import ExponentialDecay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) The `MNIST` Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ“š Tensorflow/Keras offers multiple [**datasets**](https://www.tensorflow.org/api_docs/python/tf/keras/datasets) to play with:\n",
    "- *Vectors*: `boston_housing` (regression)\n",
    "- *Images* : `mnist`, `fashion_mnist`, `cifar10`, `cifar100` (classification)\n",
    "- *Texts*: `imbd`, `reuters` (classification/sentiment analysis)\n",
    "\n",
    "\n",
    "ğŸ’¾ You can **load the MNIST dataset** with the following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T08:32:37.068956Z",
     "iopub.status.busy": "2025-08-15T08:32:37.067968Z",
     "iopub.status.idle": "2025-08-15T08:32:37.472536Z",
     "shell.execute_reply": "2025-08-15T08:32:37.468862Z",
     "shell.execute_reply.started": "2025-08-15T08:32:37.068918Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((60000, 28, 28), (60000,)), ((10000, 28, 28), (10000,)))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import datasets\n",
    "\n",
    "\n",
    "# Loading the MNIST Dataset...\n",
    "(X_train, y_train), (X_test, y_test) = datasets.mnist.load_data(path=\"mnist.npz\")\n",
    "\n",
    "# The train set contains 60 000 images, each of them of size 28x28\n",
    "# The test set contains 10 000 images, each of them of size 28x28\n",
    "(X_train.shape, y_train.shape), (X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1.1) Exploring the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â“ **Question: Let's have look at some handwritten digits of this MNIST dataset.** â“\n",
    "\n",
    "ğŸ–¨ Print some images from the *train set*.\n",
    "\n",
    "<details>\n",
    "    <summary><i>Hints</i></summary>\n",
    "\n",
    "ğŸ’¡*Hint*: use the `imshow` function from `matplotlib` with `cmap = \"gray\"`\n",
    "\n",
    "ğŸ¤¨ Note: if you don't specify this *cmap* argument, the weirdly displayed colors are just Matplotlib defaults...\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T08:32:37.475317Z",
     "iopub.status.busy": "2025-08-15T08:32:37.473936Z",
     "iopub.status.idle": "2025-08-15T08:32:37.832638Z",
     "shell.execute_reply": "2025-08-15T08:32:37.831124Z",
     "shell.execute_reply.started": "2025-08-15T08:32:37.475263Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f7db5376810>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "plt.imshow(X_train[89])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1.2) Image Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â—ï¸ **Neural Networks converge faster when the input data is somehow normalized** â—ï¸\n",
    "\n",
    "ğŸ‘©ğŸ»â€ğŸ« How do we proceed for Convolutional Neural Networks ?\n",
    "* The `RBG` intensities are coded between 0 and 255. \n",
    "* We can simply divide the input data by the maximal value 255 to have all the pixels' intensities between 0 and 1 ğŸ˜‰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â“ **Question â“ As a first preprocessing step, please normalize your data.** \n",
    "\n",
    "Don't forget to do it both on your train data and your test data.\n",
    "\n",
    "(*Note: you can also center your data, by subtracting 0.5 from all the values, but it is not mandatory*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T08:32:37.836107Z",
     "iopub.status.busy": "2025-08-15T08:32:37.835522Z",
     "iopub.status.idle": "2025-08-15T08:32:37.977407Z",
     "shell.execute_reply": "2025-08-15T08:32:37.976375Z",
     "shell.execute_reply.started": "2025-08-15T08:32:37.836024Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1.3) Inputs' dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T08:32:37.979480Z",
     "iopub.status.busy": "2025-08-15T08:32:37.978785Z",
     "iopub.status.idle": "2025-08-15T08:32:37.986674Z",
     "shell.execute_reply": "2025-08-15T08:32:37.984653Z",
     "shell.execute_reply.started": "2025-08-15T08:32:37.979431Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ‘† Remember that you have 60,000 training images and 10,000 test images, each of size $(28, 28)$. However...\n",
    "\n",
    "> â—ï¸  **`Convolutional Neural Network models need to be fed with images whose last dimension is the number of channels`.**  \n",
    "\n",
    "> ğŸ§‘ğŸ»â€ğŸ« The shape of tensors fed into ***ConvNets*** is the following: `(NUMBER_OF_IMAGES, HEIGHT, WIDTH, CHANNELS)`\n",
    "\n",
    "ğŸ•µğŸ»This last dimension is clearly missing here. Can you guess the reason why?\n",
    "<br>\n",
    "<details>\n",
    "    <summary><i>Answer<i></summary>\n",
    "        \n",
    "* All these $60000$ $ (28 \\times 28) $ pictures are black-and-white $ \\implies $ Each pixel lives on a spectrum from full black (0) to full white (1).\n",
    "        \n",
    "    * Theoretically, you don't need to know the number of channels for a black-and-white picture since there is only 1 channel (the \"whiteness\" of \"blackness\" of a pixel). However, it is still mandatory for the model to have this number of channels explicitly stated.\n",
    "        \n",
    "    * In comparison, colored pictures need multiple channels:\n",
    "        - the RGB system with 3 channels (<b><span style=\"color:red\">Red</span> <span style=\"color:green\">Green</span> <span style=\"color:blue\">Blue</span></b>)\n",
    "        - the CYMK system  with 4 channels (<b><span style=\"color:cyan\">Cyan</span> <span style=\"color:magenta\">Magenta</span> <span style=\"color:yellow\">Yellow</span> <span style=\"color:black\">Black</span></b>)\n",
    "        \n",
    "        \n",
    "</details>        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â“ **Question: expanding dimensions** â“\n",
    "\n",
    "* Use the **`expand_dims`** to add one dimension at the end of the training data and test data.\n",
    "\n",
    "* Then, print the shapes of `X_train` and `X_test`. They should respectively be equal to $(60000, 28, 28, 1)$ and $(10000, 28, 28, 1)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T08:32:37.989562Z",
     "iopub.status.busy": "2025-08-15T08:32:37.988322Z",
     "iopub.status.idle": "2025-08-15T08:32:38.003658Z",
     "shell.execute_reply": "2025-08-15T08:32:38.002260Z",
     "shell.execute_reply.started": "2025-08-15T08:32:37.989508Z"
    }
   },
   "outputs": [],
   "source": [
    "# from keras.ops import expand_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T08:32:38.005750Z",
     "iopub.status.busy": "2025-08-15T08:32:38.004939Z",
     "iopub.status.idle": "2025-08-15T08:32:38.857804Z",
     "shell.execute_reply": "2025-08-15T08:32:38.856398Z",
     "shell.execute_reply.started": "2025-08-15T08:32:38.005697Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (10000, 28, 28)\n",
      "(60000, 28, 28, 1) (10000, 28, 28, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-15 10:32:38.341538: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 376320000 exceeds 10% of free system memory.\n",
      "2025-08-15 10:32:38.797022: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 62720000 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "# a = np.array([1,2,3,4,5])\n",
    "# print(a.shape)\n",
    "# a = expand_dims(a, 1)\n",
    "# print(a.shape, a)\n",
    "\n",
    "# expand.dims adds a dimension at the specified position in the shape output\n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "\n",
    "X_train = expand_dims(X_train, 3)\n",
    "X_test = expand_dims(X_test, 3)\n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1.4) Target encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One more thing to do for a multiclass classification task in Deep Leaning:\n",
    "\n",
    "ğŸ‘‰ _\"one-hot-encode\" the categories*_\n",
    "\n",
    "â“ **Question: encoding the labels** â“ \n",
    "\n",
    "* Use **`to_categorical`** to transform your labels. \n",
    "* Store the results into two variables that you can call **`y_train_cat`** and **`y_test_cat`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T08:35:21.962328Z",
     "iopub.status.busy": "2025-08-15T08:35:21.961595Z",
     "iopub.status.idle": "2025-08-15T08:35:21.977072Z",
     "shell.execute_reply": "2025-08-15T08:35:21.975730Z",
     "shell.execute_reply.started": "2025-08-15T08:35:21.962126Z"
    }
   },
   "outputs": [],
   "source": [
    "# pd.Series(y_test).unique()\n",
    "y_train_cat = to_categorical(y_train, num_classes=10)\n",
    "y_test_cat = to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T08:35:25.582396Z",
     "iopub.status.busy": "2025-08-15T08:35:25.580419Z",
     "iopub.status.idle": "2025-08-15T08:35:25.588205Z",
     "shell.execute_reply": "2025-08-15T08:35:25.586799Z",
     "shell.execute_reply.started": "2025-08-15T08:35:25.581984Z"
    }
   },
   "outputs": [],
   "source": [
    "# Quick check that you correctly used to_categorical\n",
    "assert(y_train_cat.shape == (60000,10))\n",
    "assert(y_test_cat.shape == (10000,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is now ready to be used. âœ…"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) The Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2.1) Architecture and compilation of a CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "â“ **Question: CNN Architecture and compilation** â“\n",
    "\n",
    "Now, let's build a <u>Convolutional Neural Network</u> that has: \n",
    "\n",
    "\n",
    "- a `Conv2D` layer with 8 filters, each of size $(4, 4)$, an input shape suitable for your task, the `relu` activation function, and `padding='same'`\n",
    "- a `MaxPool2D` layer with a `pool_size` equal to $(2, 2)$\n",
    "- a second `Conv2D` layer with 16 filters, each of size $(3, 3)$, and the `relu` activation function\n",
    "- a second `MaxPool2D` layer with a `pool_size` equal to $(2, 2)$\n",
    "\n",
    "\n",
    "- a `Flatten` layer\n",
    "- a first `Dense` layer with 10 neurons and the `relu` activation function\n",
    "- a last (predictive) layer that is suited for your task\n",
    "\n",
    "In the function that initializes this model, do not forget to include the <u>compilation of the model</u>, which:\n",
    "* optimizes the `categorical_crossentropy` loss function,\n",
    "* with the `adam` optimizer, \n",
    "* and the `accuracy` as the metrics\n",
    "\n",
    "(*Note: you could add more classification metrics if you want but the dataset is well balanced!*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T09:17:58.812326Z",
     "iopub.status.busy": "2025-08-15T09:17:58.811686Z",
     "iopub.status.idle": "2025-08-15T09:17:58.825261Z",
     "shell.execute_reply": "2025-08-15T09:17:58.823442Z",
     "shell.execute_reply.started": "2025-08-15T09:17:58.812270Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def initialize_model():\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Input(shape=(28, 28, 1)))\n",
    "    \n",
    "    ### First Convolution & MaxPooling\n",
    "    # YOUR CODE HERE\n",
    "    model.add(layers.Conv2D(8, (4,4), padding='same', activation='relu'))\n",
    "    model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "   \n",
    "\n",
    "    ### Second Convolution & MaxPooling\n",
    "    # YOUR CODE HERE\n",
    "    model.add(layers.Conv2D(16, (3,3), padding='same', activation='relu'))\n",
    "    model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "    ### Flattening\n",
    "    # YOUR CODE HERE\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    ### One Fully Connected layer - \"Fully Connected\" is equivalent to saying \"Dense\"\n",
    "    # YOUR CODE HERE\n",
    "    model.add(layers.Dense(10, activation='relu'))\n",
    "\n",
    "    ### Last layer - Classification Layer with 10 outputs corresponding to 10 digits\n",
    "    # YOUR CODE HERE\n",
    "    model.add(layers.Dense(10, activation='sigmoid'))\n",
    "\n",
    "    ### Model compilation\n",
    "    # YOUR CODE HERE\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer='adam',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â“ **Question: number of trainable parameters in a convolutional layer** â“ \n",
    "\n",
    "How many trainable parameters are there in your model?\n",
    "1. Compute them with ***model.summary( )*** first\n",
    "2. Recompute them manually to make sure you properly understood ***what influences the number of weights in a CNN***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T09:17:59.610349Z",
     "iopub.status.busy": "2025-08-15T09:17:59.609815Z",
     "iopub.status.idle": "2025-08-15T09:17:59.791132Z",
     "shell.execute_reply": "2025-08-15T09:17:59.787345Z",
     "shell.execute_reply.started": "2025-08-15T09:17:59.610298Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)      â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)      â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,168</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,850</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m8\u001b[0m)      â”‚           \u001b[38;5;34m136\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling2d_5 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m8\u001b[0m)      â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m16\u001b[0m)     â”‚         \u001b[38;5;34m1,168\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling2d_6 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m16\u001b[0m)       â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             â”‚         \u001b[38;5;34m7,850\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             â”‚           \u001b[38;5;34m110\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,264</span> (36.19 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,264\u001b[0m (36.19 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,264</span> (36.19 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,264\u001b[0m (36.19 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "model = initialize_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2.2) Training a CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â“ **Question: training a CNN** â“ \n",
    "\n",
    "Initialize your model and fit it on the train data. \n",
    "- Do not forget to use a **Validation Set/Split** and an **Early Stopping criterion**. \n",
    "- Limit yourself to 5 epochs max in this challenge, just to save some precious time for the more advanced challenges!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T09:18:01.189823Z",
     "iopub.status.busy": "2025-08-15T09:18:01.189240Z",
     "iopub.status.idle": "2025-08-15T09:18:01.203249Z",
     "shell.execute_reply": "2025-08-15T09:18:01.201891Z",
     "shell.execute_reply.started": "2025-08-15T09:18:01.189779Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T09:18:01.683489Z",
     "iopub.status.busy": "2025-08-15T09:18:01.683033Z",
     "iopub.status.idle": "2025-08-15T09:21:00.073744Z",
     "shell.execute_reply": "2025-08-15T09:21:00.072684Z",
     "shell.execute_reply.started": "2025-08-15T09:18:01.683438Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 12ms/step - accuracy: 0.8375 - loss: 0.5096 - val_accuracy: 0.9672 - val_loss: 0.1133\n",
      "Epoch 2/5\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 10ms/step - accuracy: 0.9719 - loss: 0.0936 - val_accuracy: 0.9712 - val_loss: 0.0910\n",
      "Epoch 3/5\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 11ms/step - accuracy: 0.9778 - loss: 0.0725 - val_accuracy: 0.9828 - val_loss: 0.0589\n",
      "Epoch 4/5\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 11ms/step - accuracy: 0.9851 - loss: 0.0509 - val_accuracy: 0.9816 - val_loss: 0.0630\n",
      "Epoch 5/5\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 11ms/step - accuracy: 0.9868 - loss: 0.0447 - val_accuracy: 0.9846 - val_loss: 0.0522\n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train_cat,\n",
    "    validation_split=0.2,\n",
    "    batch_size=16,\n",
    "    epochs=5,\n",
    "    shuffle=True,\n",
    "    callbacks=[es]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â“ **Question: How many iterations does the CNN perform per epoch** â“\n",
    "\n",
    "_Note: it has nothing to do with the fact that this is a CNN. This is related to the concept of forward/backward propagation already covered during the previous lecture on optimizers, fitting, and losses ğŸ˜‰_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "source": [
    "> YOUR ANSWER HERE 3000 = 60000 x 0.8 /16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary><i>Answer</i></summary>\n",
    "\n",
    "With `verbose = 1` when fitting your model, you have access to crucial information about your training procedure.\n",
    "    \n",
    "Remember that we've just trained our CNN model on $60000$ training images\n",
    "\n",
    "If the chosen batch size is 32: \n",
    "\n",
    "* For each epoch, we have $ \\large \\lceil \\frac{60000}{32} \\rceil = 1875$ minibatches <br/>\n",
    "* The _validation_split_ is equal to $0.3$ - which means that within one single epoch, there are:\n",
    "    * $ \\lceil 1875 \\times (1 - 0.3) \\rceil = \\lceil 1312.5 \\rceil = 1313$ batches are used to compute the `train_loss` \n",
    "    * $ 1875 - 1312 = 562 $ batches are used to compute the `val_loss`\n",
    "    * **The parameters are updated 1313 times per epoch** as there are 1313 forward/backward propagations per epoch !!!\n",
    "\n",
    "\n",
    "ğŸ‘‰ With so many updates of the weights within one epoch, you can understand why this CNN model converges even with a limited number of epochs.\n",
    "\n",
    "</details>    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2.3) Evaluating its performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â“ **Question: Evaluating your CNN** â“ \n",
    "\n",
    "What is your **`accuracy on the test set?`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T09:23:11.967760Z",
     "iopub.status.busy": "2025-08-15T09:23:11.967228Z",
     "iopub.status.idle": "2025-08-15T09:23:14.961685Z",
     "shell.execute_reply": "2025-08-15T09:23:14.960256Z",
     "shell.execute_reply.started": "2025-08-15T09:23:11.967715Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9843 - loss: 0.0491\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "res = model.evaluate(X_test, y_test_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T09:23:46.494395Z",
     "iopub.status.busy": "2025-08-15T09:23:46.493084Z",
     "iopub.status.idle": "2025-08-15T09:23:46.502123Z",
     "shell.execute_reply": "2025-08-15T09:23:46.500908Z",
     "shell.execute_reply.started": "2025-08-15T09:23:46.494337Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set =  0.9868999719619751\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy on the test set = ', res[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ‰ You should already be impressed by your CNN skills! Reaching over 95% accuracy!\n",
    "\n",
    "ğŸ”¥ You solved what was a very hard problem 30 years ago with your own CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ **Congratulations!**\n",
    "\n",
    "ğŸ’¾ Don't forget to `git add/commit/push` your notebook...\n",
    "\n",
    "ğŸš€ ... and move on to the next challenge!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
